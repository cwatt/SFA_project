panel.grid.minor = element_blank()) +
geom_smooth(method='lm')
# NPOC drift regression
drift.fix = lm(prop_drift ~ seconds_avg, data=ints.summary)
drift.fix = tidy(drift.fix)
drift.fix = as.data.frame(drift.fix)
# Re-calculate sample concentrations based on std curve
samples <- samples %>%
mutate(Corr.Conc.=(Area-cal.NPOC[1,2])/(cal.NPOC[2,2]))
# Convert date/time to POSIXct
samples$date_time_new = as.POSIXct(samples$date_time, format="%m/%d/%Y %H:%M")
# Create time elapsed (minutes) since first internal check
samples = samples %>%
mutate(time_elapsed = round(date_time_new - t1[1,1], 2)) %>% # time elapsed since first internal check
mutate(time_elapsed = time_elapsed*3600) # convert to seconds to match drift calibration
head(samples)
# Create time elapsed since first internal check
samples = samples %>%
mutate(time_elapsed = round(date_time_new - t1[1,1], 2)) %>% # time elapsed since first internal check
mutate(time_elapsed = as.numeric(time_elapsed*3600)) # convert to seconds to match drift calibration
head(samples)
# NPOC drift correction
samples = mutate(samples, drift.conc = Corr.Conc./(min.elapsed*drift.fix[2,2]+drift.fix[1,2]))
# NPOC drift correction
samples = mutate(samples, drift.Conc = Corr.Conc./(time_elapsed*drift.fix[2,2]+drift.fix[1,2]))
head(samples)
# Correct for hand-dilution (not dilutions done by Shimadzu, which are already accounted for)
samples.final <- samples %>% mutate(FinalConc. = drift.conc*dil)
# Correct for hand-dilution (not dilutions done by Shimadzu, which are already accounted for)
samples.final <- samples %>% mutate(doc = drift.Conc*dil)
# Remove blanks from data (no longer needed)
samples.final <- samples.final[!samples.final$s.type=="Blank",]
# Remove blanks from data (no longer needed)
samples.final <- samples.final[!samples.final$sample_type=="Blank",]
head(samples.final)
head(samples.final.avg)
# Average injections for same sample
samples.final.avg <- samples.final %>%
group_by(sample_type, sample_id) %>%
summarize(mean = mean(doc))
head(samples.final.avg)
samples.final.summary$mean <- round(samples.final.summary$mean, 2)
samples.final.avg$doc <- round(samples.final.summary$mean, 2)
samples.final.avg$doc <- round(samples.final.avg$doc, 2)
head(samples.final.avg)
saveRDS(samples.final.avg, "data_DOC/SFA2/SFA2_doc.rds")
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(results = "show")
rm(list=ls())
library(plyr)
library(tidyverse)
require(broom)
library(reshape2)
library(qqplotr)
library(car)
# Import data
doc = readRDS("data_DOC/SFA2/SFA2_doc.rds")
head(doc)
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(results = "show")
rm(list=ls())
library(plyr)
library(tidyverse)
require(broom)
library(reshape2)
library(qqplotr)
library(car)
# Import data
doc = readRDS("data_DOC/SFA2/SFA2_doc.rds")
# Import metadata
meta = read.csv("data_DOC/SFA1.5/SFA1.5_DOC_metadata.csv")
head(doc)
head(doc)
?inner_join
# Merge
doc.meta = inner_join(meta, doc, by=c("Sample", "sample_id"))
# Merge
doc.meta = inner_join(meta, doc, by=c("Sample" = "sample_id"))
# Merge
doc.meta = full_join(meta, doc, by=c("Sample" = "sample_id"))
head(meta)
# Import metadata
meta = read.csv("data_DOC/SFA2/SFA2_doc_metadata.csv")
# Merge
doc.meta = full_join(meta, doc, by=c("Sample" = "sample_id"))
head(meta)
head(doc)
# Import data
doc = readRDS("data_DOC/SFA2/SFA2_doc.rds") %>%
mutate(sample_id = as.numeric(sample_id))
head(doc)
# Import metadata
meta = read.csv("data_DOC/SFA2/SFA2_doc_metadata.csv")
# Merge
doc.meta = full_join(meta, doc, by=c("Sample" = "sample_id"))
head(doc.meta)
# Merge
doc.meta = full_join(meta, doc, by=c("Sample" = "sample_id")) %>%
rename(DOC = "mean")
?rename
# Merge
doc.meta = full_join(meta, doc, by=c("Sample" = "sample_id")) %>%
rename(DOC = mean)
head(doc)
# Import data
doc = readRDS("data_DOC/SFA2/SFA2_doc.rds") %>%
mutate(sample_id = as.numeric(sample_id)) %>%
select(sample_id, mean = DOC)
# Import data
doc = readRDS("data_DOC/SFA2/SFA2_doc.rds") %>%
mutate(sample_id = as.numeric(sample_id)) %>%
select(sample_id, mean = "DOC")
# Import data
doc = readRDS("data_DOC/SFA2/SFA2_doc.rds") %>%
mutate(sample_id = as.numeric(sample_id)) %>%
select(sample_id, "DOC"=mean)
head(Doc)
head(doc)
# Import data
doc = readRDS("data_DOC/SFA2/SFA2_doc.rds") %>%
mutate(sample_id = as.numeric(sample_id)) %>%
select(sample_id, "doc"=mean)
head(doc)
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(results = "show")
knitr::opts_knit$set(root.dir = '~/SFAgrowthrate/SFAphase1.5')
rm(list=ls())
library(tidyverse)
require(broom)
sessionInfo()
# Names of external/internal checks and samples as entered into Shimadzu software
stds.name <- "Std"
int1.name <- 'Internal'
sam1.name <- 'Sample'
blank.name <- 'Blank'
#expblank.name <- 'Sample blank'
# Internal check info
int.ppm <- 25 # expected concentration of internal checks in ppm
# Sample dilution info
dil <- 23 # hand-dilution of samples before running
# Import raw data with header notes removed manually in excel or text editor
# The data was export in two separate files, one for the standards and one for the samples
raw = read_csv("~/SFAgrowthrate/data_DOC/SFA2/toc_results_01212021.csv")
# Clean up
raw.clean = raw %>%
filter(Excluded == 0) %>% # remove excluded injections
rename(date_time = 'Date / Time', sample_type = 'Sample Name', analys_type = 'Analysis(Inj.)', sample_id = 'Sample ID') %>% # rename columns
select(1,3:4,9,12:14) # remove junk columns
# NPOC drift regression
drift.fix = lm(prop_drift ~ seconds_avg, data=ints.summary)
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(results = "show")
knitr::opts_knit$set(root.dir = '~/SFAgrowthrate/SFAphase1.5')
rm(list=ls())
library(tidyverse)
require(broom)
sessionInfo()
# Names of external/internal checks and samples as entered into Shimadzu software
stds.name <- "Std"
int1.name <- 'Internal'
sam1.name <- 'Sample'
blank.name <- 'Blank'
#expblank.name <- 'Sample blank'
# Internal check info
int.ppm <- 25 # expected concentration of internal checks in ppm
# Sample dilution info
dil <- 23 # hand-dilution of samples before running
# Import raw data with header notes removed manually in excel or text editor
# The data was export in two separate files, one for the standards and one for the samples
raw = read_csv("~/SFAgrowthrate/data_DOC/SFA2/toc_results_01212021.csv")
# Clean up
raw.clean = raw %>%
filter(Excluded == 0) %>% # remove excluded injections
rename(date_time = 'Date / Time', sample_type = 'Sample Name', analys_type = 'Analysis(Inj.)', sample_id = 'Sample ID') %>% # rename columns
select(1,3:4,9,12:14) # remove junk columns
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(results = "show")
knitr::opts_knit$set(root.dir = '~/SFAgrowthrate/SFAphase1.5')
rm(list=ls())
library(tidyverse)
require(broom)
sessionInfo()
# Names of external/internal checks and samples as entered into Shimadzu software
stds.name <- "Std"
int1.name <- 'Internal'
sam1.name <- 'Sample'
blank.name <- 'Blank'
#expblank.name <- 'Sample blank'
# Internal check info
int.ppm <- 25 # expected concentration of internal checks in ppm
# Sample dilution info
dil <- 23 # hand-dilution of samples before running
# Import raw data with header notes removed manually in excel or text editor
# The data was export in two separate files, one for the standards and one for the samples
raw = read_csv("~/SFAgrowthrate/data_DOC/SFA2/toc_results_01212021.csv")
head(raw)
# Clean up
raw.clean = raw %>%
filter(Excluded == 0) %>% # remove excluded injections
select(1,3:4,9,12:14) # remove junk columns
head(raw.clean)
# Import raw data with header notes removed manually in excel or text editor
# The data was export in two separate files, one for the standards and one for the samples
raw = read_csv("~/SFAgrowthrate/data_DOC/SFA2/toc_results_01212021.csv")
# Clean up
raw.clean = raw %>%
filter(Excluded == 0) %>% # remove excluded injections
select(1,3:4,9,12:14) %>% # remove junk columns
rename(date_time = 'Date / Time', sample_type = 'Sample Name', analys_type = 'Analysis(Inj.)', sample_id = 'Sample ID') %>% # rename columns
# Subset standard data and remove unnecessary columns
stds = raw.clean[which(raw.clean$sample_type == stds.name),]
# Clean up
raw.clean = raw %>%
filter(Excluded == 0) %>% # remove excluded injections
select(1,3:4,9,12:14) %>% # remove junk columns
rename(date_time = 'Date / Time', sample_type = 'Sample Name', analys_type = 'Analysis(Inj.)', sample_id = 'Sample ID') # rename columns
# Import raw data with header notes removed manually in excel or text editor
# The data was export in two separate files, one for the standards and one for the samples
raw = read_csv("~/SFAgrowthrate/data_DOC/SFA2/toc_results_01212021.csv")
# Clean up
raw.clean = raw %>%
filter(Excluded == 0) %>% # remove excluded injections
select(1,3:4,9,12:14) %>% # remove junk columns
rename(date_time = 'Date / Time', sample_type = 'Sample Name', analys_type = 'Analysis(Inj.)', sample_id = 'Sample ID') # rename columns
?rename
head(raw)
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(results = "show")
knitr::opts_knit$set(root.dir = '~/SFAgrowthrate/SFAphase1.5')
rm(list=ls())
library(tidyverse)
require(broom)
sessionInfo()
# Names of external/internal checks and samples as entered into Shimadzu software
stds.name <- "Std"
int1.name <- 'Internal'
sam1.name <- 'Sample'
blank.name <- 'Blank'
#expblank.name <- 'Sample blank'
# Internal check info
int.ppm <- 25 # expected concentration of internal checks in ppm
# Sample dilution info
dil <- 23 # hand-dilution of samples before running
# Import raw data with header notes removed manually in excel or text editor
# The data was export in two separate files, one for the standards and one for the samples
raw = read_csv("~/SFAgrowthrate/data_DOC/SFA2/toc_results_01212021.csv")
# Clean up
raw.clean = raw %>%
filter(Excluded == 0) %>% # remove excluded injections
select(1,3:4,9,12:14) %>% # remove junk columns
rename(date_time = 'Date / Time', sample_type = 'Sample Name', analys_type = 'Analysis(Inj.)', sample_id = 'Sample ID') # rename columns
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(results = "show")
rm(list=ls())
library(tidyverse)
require(broom)
library(reshape2)
library(qqplotr)
library(car)
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(results = "show")
knitr::opts_knit$set(root.dir = '~/SFAgrowthrate/SFAphase1.5')
rm(list=ls())
library(tidyverse)
require(broom)
sessionInfo()
# Names of external/internal checks and samples as entered into Shimadzu software
stds.name <- "Std"
int1.name <- 'Internal'
sam1.name <- 'Sample'
blank.name <- 'Blank'
#expblank.name <- 'Sample blank'
# Internal check info
int.ppm <- 25 # expected concentration of internal checks in ppm
# Sample dilution info
dil <- 23 # hand-dilution of samples before running
# Import raw data with header notes removed manually in excel or text editor
# The data was export in two separate files, one for the standards and one for the samples
raw = read_csv("~/SFAgrowthrate/data_DOC/SFA2/toc_results_01212021.csv")
# Clean up
raw.clean = raw %>%
filter(Excluded == 0) %>% # remove excluded injections
select(1,3:4,9,12:14) %>% # remove junk columns
rename(date_time = 'Date / Time', sample_type = 'Sample Name', analys_type = 'Analysis(Inj.)', sample_id = 'Sample ID') # rename columns
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(results = "show")
knitr::opts_knit$set(root.dir = '~/SFAgrowthrate/SFAphase1.5')
rm(list=ls())
library(tidyverse)
require(broom)
sessionInfo()
# Names of external/internal checks and samples as entered into Shimadzu software
stds.name <- "Std"
int1.name <- 'Internal'
sam1.name <- 'Sample'
blank.name <- 'Blank'
#expblank.name <- 'Sample blank'
# Internal check info
int.ppm <- 25 # expected concentration of internal checks in ppm
# Sample dilution info
dil <- 23 # hand-dilution of samples before running
# Import raw data with header notes removed manually in excel or text editor
# The data was export in two separate files, one for the standards and one for the samples
raw = read_csv("~/SFAgrowthrate/data_DOC/SFA2/toc_results_01212021.csv")
# Clean up
raw.clean = raw %>%
filter(Excluded == 0) %>% # remove excluded injections
select(1,3:4,9,12:14) %>% # remove junk columns
rename(date_time = 'Date / Time', sample_type = 'Sample Name', analys_type = 'Analysis(Inj.)', sample_id = 'Sample ID') # rename columns
# Subset standard data and remove unnecessary columns
stds = raw.clean[which(raw.clean$sample_type == stds.name),]
# Subset internal checks
ints = raw.clean[which(raw.clean$sample_type == int1.name),]
# Subset samples
samples = raw.clean[which(raw.clean$sample_type == sam1.name | raw.clean$sample_type == blank.name),]
# NPOC
npoc.lm = lm(Area ~ Conc., data = stds)
plot(Area ~ Conc., data = stds, main = "Initial Cal Curve NPOC") +
abline(npoc.lm)
summary(npoc.lm)
cal.NPOC <- as.data.frame(tidy(npoc.lm))
# Convert date/time to POSIXct (format= specifies input format)
ints$date_time_new = as.POSIXct(ints$date_time, format="%m/%d/%Y %H:%M")
head(ints)
# Remove internal check 1
ints.rm = filter(ints, !sample_id==1)
# Replace with std 10 ppm from calibration curve
stds.10ppm = filter(stds, Conc.==10) # isolate 10 ppm std
ints.rp = stds.10ppm %>%
bind_rows(ints.rm) %>% # add to internal check data
mutate(date_time_new = as.POSIXct(date_time, format="%m/%d/%Y %H:%M")) # fix date and time for replacement
# Time of first check
t1 = as.data.frame(ints.rp[1,8])
# Create time elapsed column
ints.rp = ints.rp %>%
mutate(seconds = round(date_time_new - t1[1,1], 2)) # time elapsed since first internal check
# Summarize mean time since start of run for each internal check group
int.times = ints.rp %>%
group_by(sample_id) %>%
summarize(seconds_avg = mean(seconds)) # this is broken for some reason, it's taking the whole avg not by grp
# Calculate concentration in internal standards based on curve
# I've found that the concentrations that the machine comes up with have no relationship to the standard curve for some reason
ints.rp = ints.rp %>%
mutate(Corr.Conc.=(Area-cal.NPOC[1,2])/(cal.NPOC[2,2]))
int.conc = ints.rp %>%
group_by(analys_type, sample_id) %>%
summarize(mean.conc = mean(Corr.Conc.))
ints.summary = inner_join(int.times, int.conc, by='sample_id')
# Calculate concentration of NPOC in standards based on standard curve
NPOC.stds.summary = stds %>%
group_by(Conc.) %>%
summarize(mean.area = mean(Area))
NPOC.stds.summary = NPOC.stds.summary %>%
mutate(calc.conc = (mean.area-cal.NPOC[1,2])/cal.NPOC[2,2])
# Actual concentrations expected from internal checks based on standard curves
NPOC.std.10ppm = NPOC.stds.summary[NPOC.stds.summary$Conc.==10,]$calc.conc # changed from 25 to 10
# Calculate percent and proportion drift
ints.summary <- ints.summary %>% mutate(percent_drift = ((mean.conc-NPOC.std.10ppm)/NPOC.std.10ppm)*100)
ints.summary <- ints.summary %>% mutate(prop_drift = (mean.conc/NPOC.std.10ppm))
# Plot internal standards over time
ggplot(ints.summary, aes(seconds_avg, percent_drift, colour = analys_type, fill = analys_type)) +
geom_point() +
labs(x = "Time (min)", y = "% Drift from Original Curve Value") +
ggtitle("Check Standard Drift - Percentage Basis") +
theme_bw() + theme(panel.grid.major = element_blank(),
panel.grid.minor = element_blank()) +
geom_smooth(method='lm')
ggplot(ints.summary, aes(seconds_avg, prop_drift, colour = analys_type, fill = analys_type)) +
geom_point() +
labs(x = "Time (min)", y = "Proportion of Original Value") +
ggtitle("Check Standard Drift - Proportional Basis") +
theme_bw() + theme(panel.grid.major = element_blank(),
panel.grid.minor = element_blank()) +
geom_smooth(method='lm')
# NPOC drift regression
drift.fix = lm(prop_drift ~ seconds_avg, data=ints.summary)
drift.fix = tidy(drift.fix)
drift.fix = as.data.frame(drift.fix)
# Re-calculate sample concentrations based on std curve
samples <- samples %>%
mutate(Corr.Conc.=(Area-cal.NPOC[1,2])/(cal.NPOC[2,2]))
# Convert date/time to POSIXct
samples$date_time_new = as.POSIXct(samples$date_time, format="%m/%d/%Y %H:%M")
# Create time elapsed since first internal check
samples = samples %>%
mutate(time_elapsed = round(date_time_new - t1[1,1], 2)) %>% # time elapsed since first internal check
mutate(time_elapsed = as.numeric(time_elapsed*3600)) # convert to seconds to match drift calibration
# NPOC drift correction
samples = mutate(samples, drift.Conc = Corr.Conc./(time_elapsed*drift.fix[2,2]+drift.fix[1,2]))
# Correct for hand-dilution (not dilutions done by Shimadzu, which are already accounted for)
samples.final <- samples %>% mutate(doc = drift.Conc*dil)
# Remove blanks from data (no longer needed)
samples.final <- samples.final[!samples.final$sample_type=="Blank",]
# Average injections for same sample
samples.final.avg <- samples.final %>%
group_by(sample_id) %>%
summarize(mean = mean(doc))
head(samples.final.avg)
saveRDS(samples.final.avg, "data_DOC/SFA2/SFA2_doc.rds")
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(results = "show")
rm(list=ls())
library(tidyverse)
require(broom)
library(reshape2)
library(qqplotr)
library(car)
# Import data
doc = readRDS("data_DOC/SFA2/SFA2_doc.rds") %>%
mutate(sample_id = as.numeric(sample_id)) %>%
select(sample_id, "doc"=mean)
head(doc)
# Import metadata
meta = read.csv("data_DOC/SFA2/SFA2_doc_metadata.csv")
# Merge
doc.meta = full_join(meta, doc, by=c("Sample" = "sample_id")) %>%
merge(meta, doc, by.y="sample_id", by.x="ucosm", all=TRUE)
# Merge
doc.meta = full_join(meta, doc, by=c("Sample" = "sample_id"))
head(doc.meta)
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(results = "show")
rm(list=ls())
library(tidyverse)
require(broom)
library(reshape2)
library(qqplotr)
library(car)
doc = readRDS("data_DOC/SFA2/SFA2_doc.rds") %>%
mutate(sample_id = as.numeric(sample_id)) %>%
select(sample_id, "doc"=mean)
# Import metadata
meta = read.csv("data_DOC/SFA2/SFA2_doc_metadata.csv")
# Merge
doc.meta = full_join(meta, doc, by=c("Sample" = "sample_id"))
head(doc.meta)
ggplot(doc.meta, aes(x=as.factor(Sample), y=doc, color=DOC_pheno)) +
geom_point() +
theme_test() +
labs(x="Sample", y="DOC conc.")
ggplot(doc.meta, aes(x=as.factor(Innoculant), y=doc, color=DOC_pheno)) +
geom_point() +
theme_test() +
labs(x="Sample", y="DOC conc.")
ggplot(doc.meta, aes(x=as.factor(Innoculant), y=doc, color=DOC_pheno)) +
geom_point() +
facet_wrap(~Group) +
theme_test() +
labs(x="Sample", y="DOC conc.")
ggplot(doc.meta, aes(x=DOC_pheno, y=doc)) +
geom_point() +
facet_wrap(~Group) +
theme_test() +
labs(x="Sample", y="DOC conc.")
ggplot(doc.meta, aes(x=DOC_pheno, y=doc, color=Sample)) +
geom_point() +
facet_wrap(~Group) +
theme_test() +
labs(x="Sample", y="DOC conc.")
head(doc.meta)
headspace.doc = filter(doc.meta, DOC_pheno=="Headspace")
head.doc.lm = lm(doc.metadoc ~ DOC_pheno, data = headspace.doc)
head.doc.lm = lm(doc ~ DOC_pheno, data = headspace.doc)
headspace.doc
headspace.doc = filter(doc.meta, Group=="Headspace")
headspace.doc
headspace.doc = filter(doc.meta, Group=="Headspace" & Type=="Sample")
headspace.doc
library(lmerTest)
?lmer
head.doc.lmer = lmer(doc ~ DOC_pheno + (1|Sample), data = headspace.doc) # linear mixed effects model, allow sample to vary independently
heaad(headspace.doc)
head(headspace.doc)
head.doc.lmer = lmer(doc ~ DOC_pheno + (1|Innoculant), data = headspace.doc) # linear mixed effects model, allow innoculant to vary independently
hist(residuals(head.doc.lmer))
plot(residuals(head.doc.lmer), predict(head.doc.lmer))
summary(head.doc.lmer)
Growth.doc = filter(doc.meta, Group=="Growth" & Type=="Sample")
growth.doc = filter(doc.meta, Group=="Growth" & Type=="Sample")
grow.doc.lmer = lmer(doc ~ DOC_pheno + (1|Innoculant), data = growth.doc) # linear mixed effects model, allow innoculant to vary independently
hist(residuals(head.doc.lmer))
hist(residuals(grow.doc.lmer))
grow.doc.lmer2 = lmer(log(doc) ~ DOC_pheno + (1|Innoculant), data = growth.doc) # linear mixed effects model, allow innoculant to vary independently
hist(residuals(grow.doc.lmer2))
plot(residuals(head.doc.lmer), predict(head.doc.lmer2))
plot(residuals(head.doc.lmer2), predict(head.doc.lmer2))
plot(residuals(grow.doc.lmer2), predict(grow.doc.lmer2))
hist(residuals(grow.doc.lmer))
hist(residuals(grow.doc.lmer2))
hist(residuals(grow.doc.lmer))
plot(residuals(grow.doc.lmer), predict(grow.doc.lmer))
grow.doc.lmer = lmer(log(doc) ~ DOC_pheno + (1|Innoculant), data = growth.doc) # linear mixed effects model, allow innoculant to vary independently
hist(residuals(grow.doc.lmer))
plot(residuals(grow.doc.lmer), predict(grow.doc.lmer))
summary(head.doc.lmer)
ggplot(doc.meta, aes(x=DOC_pheno, y=doc)) +
geom_boxplot() +
facet_wrap(~Group) +
theme_test() +
labs(x="Sample", y="DOC conc.")
headspace.doc = filter(doc.meta, Group=="Headspace" & Type=="Sample")
head.doc.lmer = lmer(doc ~ DOC_pheno, data = headspace.doc) # linear mixed effects model, allow innoculant to vary independently
headspace.doc = filter(doc.meta, Group=="Headspace" & Type=="Sample")
head.doc.lmer = lm(doc ~ DOC_pheno, data = headspace.doc) # linear mixed effects model, allow innoculant to vary independently
hist(residuals(head.doc.lmer))
plot(residuals(head.doc.lmer), predict(head.doc.lmer))
summary(head.doc.lmer)
headspace.doc = filter(doc.meta, Group=="Headspace" & Type=="Sample")
head.doc.lmer = lmer(doc ~ DOC_pheno + (1|Innoculant), data = headspace.doc) # linear mixed effects model, allow innoculant to vary independently
hist(residuals(head.doc.lmer))
plot(residuals(head.doc.lmer), predict(head.doc.lmer))
summary(head.doc.lmer)
