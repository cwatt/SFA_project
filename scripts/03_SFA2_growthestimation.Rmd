---
title: "SFA2 - Growth estimations"
author: "Cassandra Wattenburger"
date: "9/22/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(results = "show")
knitr::opts_chunk$set(message = FALSE)
```

```{r}
# Clear working directory, load in packages, generate package info
rm(list=ls())

library("tidyverse")
library("trelliscopejs")

sessionInfo()
```

### Import data

* Normalized count data
* Taxonomy table
* Metadata

See 02.5_SFA2_preprocess_redos.Rmd.

```{r}
# Count data
count_norm <- readRDS("../data_intermediate/SFA2_count_normalized.rds") %>% 
  gather(SampleID, ARNIS_ratio, -ASV) %>% 
  mutate(SampleID = as.double(gsub("sa", "", SampleID)))

# Taxonomy
tax <- readRDS("../data_intermediate/SFA2_tax_processed.rds") %>% 
  rownames_to_column(var="ASV")

# Metadata
meta <- read_tsv("../data_amplicon/SFA2_full/SFA2_full_metadata.tsv")

# Merge
norm <- inner_join(count_norm, tax, by="ASV") %>% 
  inner_join(meta, by="SampleID") %>% 
  select(c(SampleID, Sample, Type:Replicate, Domain:Species, ASV, ARNIS_ratio)) %>% 
  mutate(Innoculant = as_factor(Innoculant),
         Replicate = as_factor(Replicate)) %>% 
  mutate(across(Domain:Species, ~as.character(.x), {.col}))
```

### Prepare data

Remove Aquifex ASV: "445e8681c3c1a735760e6c394f5f4d0a"

```{r}
norm_prep <- norm %>% 
  filter(ASV != "445e8681c3c1a735760e6c394f5f4d0a")
```

Remove samples that did not contain internal standard

* These are now Inf because previous script attempted to divide by 0

```{r}
norm_prep <- norm_prep[!is.infinite(norm_prep$ARNIS_ratio),]
```

Remove non-present taxa

```{r}
norm_prep <- norm_prep %>% 
  filter(ARNIS_ratio != 0)
```

Average across technical replicates

* For better coverage of time series

```{r}
norm_prep <- norm_prep %>% 
  group_by(Type, Innoculant, DOC, Day, Domain, Phylum, Class, Order, Family, Genus, Species, ASV) %>% 
  summarize(ARNIS_ratio_avg = mean(ARNIS_ratio, na.rm = TRUE))
```

Remove taxa that didn't occur in at least four time points

```{r}
# Identify ASVs with less than 4 time points
norm_occurs <- norm_prep %>% 
  group_by(ASV, Type, Innoculant) %>% 
  summarize(occurs = n()) %>% 
  filter(occurs > 3)

# Filter
norm_prep <- inner_join(norm_prep, norm_occurs, by=c("ASV", "Innoculant", "Type")) %>% 
  select(everything(), -occurs)
```

Natural log transform

```{r}
norm_prep <- norm_prep %>% 
  mutate(ln_ARNIS = log(ARNIS_ratio_avg))
```

Create unique label for each ASV and time series

```{r}
norm_prep <- norm_prep %>%
  mutate(label = paste0(Type, Innoculant, "_", ASV))
```


# Visualize time series

All ASVS:

```{r, eval=FALSE}
# Slow
# Opens in browser
norm_prep %>% 
  filter(Type=="Growth") %>% 
  ggplot(aes(x=Day, y=ln_ARNIS, color=Innoculant)) +
  facet_wrap(~DOC) +
  geom_point() +
  geom_line() +
  facet_trelliscope(~ASV, scales="free_y", path="rmarkdown_files", self_contained=TRUE, height = 400, width = 1600) +
  labs(y="ln ARNIS ratio", x="Day") +
  theme_test()
```

Specific examples:

```{r}
# Function to extract taxonomic info for graphs
extract_tax <- function(df, asv, level) { # Data frame, "ASV", "Taxonomy level"
  temp <- df %>% 
    filter(ASV == asv)
  tax <- unique(temp[[level]])
  return(tax)
  }

# Time series graphing function
graph_timeseries <- function(df, asv) {
  graph <- df %>%
    filter(ASV==asv) %>% 
    ggplot(aes(x=Day, y=ln_ARNIS, color=Innoculant)) +
    facet_wrap(~DOC) +
    geom_point() +
    geom_line() +
    labs(y="ln ARNIS ratio", x="Day", title=paste0(extract_tax(norm_prep, asv, "Phylum"), ", ", 
                                                            extract_tax(norm_prep, asv, "Genus"))) +
    theme_test()
  return(graph)
}
```

```{r}
# Graph

# Robust growth
graph_timeseries(norm_prep, "fed2377b60ef09790fc532bbbe2b4602")
graph_timeseries(norm_prep, "0134683a521e4c34adf2d515cbbca84d")
graph_timeseries(norm_prep, "1030f18ec1c231043abead5e7c3ac109")
graph_timeseries(norm_prep, "4205b2d577048e1da9d9712f9476cd7b")

# Less robust growth
graph_timeseries(norm_prep, "29be7b1a76d1f575ef3ee8d7cc10f0b1")
graph_timeseries(norm_prep, "30a0483ea3c97871b3c91f489fb13ece")
graph_timeseries(norm_prep, "32102f31db06d8a0411da55c4102a9f9")
graph_timeseries(norm_prep, "438ef58af72cb79f6a9220a0b79e976b")
graph_timeseries(norm_prep, "4d0009900aead37d86f6c0a59ee97de3")
graph_timeseries(norm_prep, "5906b37863a7a985418e910925a659ec")
graph_timeseries(norm_prep, "5ce5182a13292aaa88c100640c03afca")
graph_timeseries(norm_prep, "67e786df4bd7ffe42b17907db62caeee")

# Death
graph_timeseries(norm_prep, "13e479df5562e8e93d620ac363eb9644")
graph_timeseries(norm_prep, "2c574662d10f5b34e3b31cdbb9839ba2")
graph_timeseries(norm_prep, "79fa5edf0f6123d3ea5c2c69b897fac1")

# Low abundance issues/noise?
graph_timeseries(norm_prep, "399eb38d8361026b8f897470becd3f13")
graph_timeseries(norm_prep, "39a1ca18bf7123d31dbc41d7c4f03214")
```

# Estimate growth

Create functions:

```{r}
# Function: Save estimate
save_fit <- function(start, end, df, output) {
  # Save estimate info
  est <- NULL; coeff <- NULL; residuals <- NULL; pval <- NULL; length <- NULL; thisrow <- data.frame() # clear previous
  est <- lm(abund ~ time, data=df[start:end,])
  coeff <- est$coefficients[2]
  residuals <- sum(abs(resid(est)))
  pval <- summary(est)$coefficients[2,4]
  length <- end - start + 1
  thisrow <- data.frame(label, start, end, length, coeff, pval, residuals, row.names <- NULL)
  output <- rbind(output, thisrow)
  return(output)
}

# Function: Fit linear estimate to the data with sliding window
## Requires a dataframe with columns containing a label, ln abundance values, time points
## df = data frame containing time series with abundance values (ln transformed), long format
## label = column with unique identifier for each time series
## abund = column with abundance values at each time point
## time = column with time point values
growth_estimate <- function(df, label, abund, time) {
  output <- data.frame()
  for (label in as.character(unique(df$label))) {
    
    # Subset one time series using the label
    df_sub <- data.frame()
    df_sub <- df[df$label==label,] 
    stop <- FALSE
    
    # Sliding window
    for (start in 1:(nrow(df_sub) - 2)) {
      stop <- FALSE
      for (end in (start + 2):nrow(df_sub)) {
        if (stop == TRUE) {break}
     
        # Fit linear model to the window
        window_lm <- NULL; window_p <- NULL; window_coeff <- NULL
        window_lm <- lm(abund ~ time, data = df_sub[start:end,])
        window_p <- summary(window_lm)$coefficients[2,4]
        window_coeff <- window_lm$coefficients[2]
  
        # If a suitable fit is found and more time points exist that were not included, try extending the window
        if (window_p <= 0.05 & window_coeff > 0 & end < nrow(df_sub)) {
          for (extend_end in ((end+1):nrow(df_sub))) {
            if (stop == TRUE) {break}
            
            # Fit linear model to the extended window
            prevwindow_lm <- NULL; prevwindow_p <- NULL; prevwindow_coeff <- NULL 
            prevwindow_lm <- lm(abund ~ time, data = df_sub[start:(extend_end - 1),])
            prevwindow_p <- summary(prevwindow_lm)$coefficients[2,4]
            prevwindow_coeff <- prevwindow_lm$coefficients[2]
            
            # Fit linear model to previous, non-extended window
            newwindow_lm <- NULL; newwindow_p <- NULL; newwindow_coeff <- NULL 
            newwindow_lm <- lm(abund ~ time, data = df_sub[start:extend_end,])
            newwindow_p <- summary(newwindow_lm)$coefficients[2,4]
            newwindow_coeff <- newwindow_lm$coefficients[2]
            
            # If see improvement and can add more data, continue extending the window
            if (newwindow_p <= prevwindow_p & newwindow_coeff > 0 & x < nrow(df_sub)) {
              next
            }
            
            # If no improvement, save the previous fit
            else if (newwindow_p > prevwindow_p & prevwindow_coeff > 0 & x < nrow(df_sub)) {
              end <- extend_end - 1
              output <- savefit(start, end, df_sub, output)
              stop <- TRUE
            }
            
            # If see improvement or no harm but no more data points to fit, save the extended fit
            else if (newwindow_p <= prevwindow_p & newwindow_coeff > 0 & extend_end == nrow(df_sub)) {
              end <- extend_end
              output <- savefit(start, end, df_sub, output)
              stop <- TRUE
            } 
          }
        }
        
        # If no more data available to add to model, save the fit
        else if (window_p <= 0.05 & window_coeff > 0 & end == nrow(df_sub)) {
          output <- savefit(start, end, datasub, estimates)
          stop <- TRUE
        }
      }
    }
  }
  
  # Rename output columns
  colnames(output) <- c("label", "start", "end", "length", "slope", "pvalue", "residuals")
  return(output)
}
```


Estimate growth characteristics:

```{r, eval=FALSE}
# SLOW
growth_estimates <- growth_estimate(norm_prep, "label", "ln_ARNIS", "Day") # fix

saveRDS(growth_estimates, file = "../data_intermediate/SFA2_growth_estimates.rds")
```

```{r}
growth_estimates <- readRDS(file = "../data_intermediate/SFA2_growth_estimates.rds")

# Add metadata to estimates
growth_estimates <- norm_prep %>% 
  select(c(Type, Innoculant, DOC_pheno, Day, Domain, Phylum, Class, Order, Family, Genus, Species, ASV, label)) %>% 
  inner_join(growth_estimates, by="label")
```




