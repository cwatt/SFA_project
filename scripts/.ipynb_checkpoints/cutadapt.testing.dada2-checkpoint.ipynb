{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project: cutadapt testing\n",
    "\n",
    "Cassandra Wattenburger, 09/13/21\n",
    "\n",
    "### Notes:\n",
    "* Adding Cutadapt to pipeline\n",
    "* Original script written by Roli Wilhelm, heavily modified by Cassandra Wattenburger\n",
    "* QIIME2 v2021.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline information\n",
    "\n",
    "### Pipeline to process raw sequences with DADA2 ###\n",
    "* Prep for import into QIIME2 (modify sequence IDs and combine two index files)\n",
    "* Import into QIIME2\n",
    "* Demultiplex\n",
    "* Denoise and merge with DADA2\n",
    "* Prepare ASV tables and representative sequences *(Note: sample names starting with a digit will break this step)*\n",
    "* Classify sequences\n",
    "* Construct phylogenetic tree\n",
    "* Export from QIIME2\n",
    "\n",
    "*100% Appropriated from the \"Atacama Desert Tutorial\" for QIIME2*\n",
    "\n",
    "### Pipeline can handle both 16S rRNA gene and ITS sequences ###\n",
    "* Tested on 515f and 806r\n",
    "* Tested on ITS1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Before you start\n",
    "\n",
    "### Commands to install dependencies ####\n",
    "##### || QIIME2 and biopython ||\n",
    "QIIME2 is still actively in development with frequent new releases. Check for the most up-to-date version and use that.\n",
    "\n",
    "Install QIIME2: \n",
    "* <https://docs.qiime2.org/2017.11/install/native/#install-qiime-2-within-a-conda-environment>, follow the instructions to install QIIME2 in Linux (64-bit).\n",
    "\n",
    "Activate the QIIME2 environment:\n",
    "* source activate [qiime2-pipeline-name]\n",
    "\n",
    "After you install and activate the QIIME2 environment, you must also install biopython for the barcode concatenation step to work. To install biopython make sure the QIIME2 environment is activated and run:\n",
    "* conda install -c anaconda biopython\n",
    "\n",
    "Install cutadapt to the QIIME2 environment as well. Cutadapt removes primers from the sequences.\n",
    "* conda install -c bioconda cutadapt\n",
    "\n",
    "##### || Copyrighter rrn database ||\n",
    "The script will automatically install the curated GreenGenes rrn attribute database: https://github.com/fangly/AmpliCopyrighter\n",
    "\n",
    "#### Citations\n",
    "* Caporaso, J. G., Kuczynski, J., Stombaugh, J., Bittinger, K., Bushman, F. D., Costello, E. K., *et al.* (2010). QIIME allows analysis of high-throughput community sequencing data. Nature methods, 7(5), 335-336.\n",
    "\n",
    "* Angly, F. E., Dennis, P. G., Skarshewski, A., Vanwonterghem, I., Hugenholtz, P., & Tyson, G. W. (2014). CopyRighter: a rapid tool for improving the accuracy of microbial community profiles through lineage-specific gene copy number correction. Microbiome, 2(1), 11.\n",
    "\n",
    "### Using jupyter notebook screens ###\n",
    "\n",
    "With the QIIME2 environment activated, open your jupyter notebook screen in the directory containing this script:\n",
    "* jupyter-n [screen-name] [port #]\n",
    "\n",
    "See [these instructions](https://github.com/buckleylab/Buckley_lab_protocols/blob/master/Using_the_server/getting_started_on_server.md#make-jupyter-notebook-screens-command) for how to set up and use this command on the server.\n",
    "\n",
    "### Directory and data organization ###\n",
    "\n",
    "This pipeline assumes that you've organized your data in a certain way:\n",
    "* Each library of raw data is contained in a separate directory\n",
    "* Each library has a separate working directory within a larger project directory\n",
    "* Tree construction assumes all 16S libraries processed together will be analyzed together, so one tree is made based on all 16S libraries and is placed in a separate tree directory within the project directory\n",
    "\n",
    "### Troubleshooting tip ###\n",
    "Replace os.system with print, and copy/paste the output into the command line to view the error message."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: User Input\n",
    "\n",
    "Metadata requirements:\n",
    "* Must be located in each library directory\n",
    "* Must be .tsv format \n",
    "* First column is named \"SampleID\" with sample names as rows\n",
    "* Contains another column named \"BarcodeSequence\" with the relevant barcode seqeunces as rows (rev. comp. reverse barcode sequence concatenated with forward barcode sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re, numpy as np\n",
    "\n",
    "# Prepare an object with the name of the library and all related file paths\n",
    "# datasets = [['library name prefix', 'processed data directory path', 'raw data directory', 'read1 file name', 'read2 file name', 'index1 file name', 'index2 file name', 'metadata file name', 'domain of life (bacteria or fungi)'], ...]\n",
    "project = \"/home/cassi/SFAgrowthrate/data_amplicon/cutadapt_testing\" # this can be the same as the library directory if you only have one library to process\n",
    "libraries = [['SFA2_nano2_cutadapt', \n",
    "             '/home/cassi/SFAgrowthrate/data_amplicon/cutadapt_testing', \n",
    "             '/home/backup_files/raw_reads/SFA2.cassi.2021/nano_v2',\n",
    "             '144191_DCP45_SFA2_nano2_S1_R1_001.fastq.gz', \n",
    "             '144191_DCP45_SFA2_nano2_S1_R2_001.fastq.gz', \n",
    "             '144191_DCP45_SFA2_nano2_S1_I1_001.fastq.gz', \n",
    "             '144191_DCP45_SFA2_nano2_S1_I2_001.fastq.gz', \n",
    "             'SFA2_nano2_metadata.tsv',\n",
    "             'bacteria']]\n",
    "\n",
    "# Set # of processors\n",
    "processors = 10\n",
    "\n",
    "# Which bacterial database will you use? Silva or GreenGenes\n",
    "db = \"Silva\"\n",
    "\n",
    "# Phylogenetic tree (non-fungal data)\n",
    "treename = \"SFA2nano2_cutadapt\" # name prefix for the tree file\n",
    "\n",
    "## Enter minimum support for keeping QIIME classification\n",
    "# Note: Classifications that do not meet this criteria will be retained, labeled 'putative'\n",
    "min_support = 0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Truncate sequence identifiers\n",
    "\n",
    "This step removes a portion at the end of the sequence ID that is incompatible with QIIME2. It will also create a modified directory in your raw data directory to house the modified data. The original raw data will not be modified, only the copies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "for library in libraries:\n",
    "    raw = library[2]\n",
    "    read1 = library[3]\n",
    "    read2 = library[4]\n",
    "    index1 = library[5]\n",
    "    index2 = library[6]\n",
    "    \n",
    "    # Create a directory to place modified_cutadapt sequence data\n",
    "    if not os.path.isdir(os.path.join(raw, \"modified_cutadapt\")):\n",
    "        !mkdir $raw/modified_cutadapt\n",
    "    \n",
    "    # Copy/paste all raw sequence data into modified_cutadapt directory\n",
    "    !cp $raw/*.fastq.gz $raw/modified_cutadapt\n",
    "    \n",
    "    # Decompress all files\n",
    "    !unpigz $raw/modified_cutadapt/*.fastq.gz\n",
    "    \n",
    "    # Decompressed file names\n",
    "    read1decomp = re.sub(\".fastq.gz\", \".fastq\", read1)\n",
    "    read2decomp = re.sub(\".fastq.gz\", \".fastq\", read2)\n",
    "    index1decomp = re.sub(\".fastq.gz\", \".fastq\", index1)\n",
    "    index2decomp = re.sub(\".fastq.gz\", \".fastq\", index2)\n",
    "    \n",
    "    # Remove problematic part of sequence IDs\n",
    "    !sed 's/\\ [0-9]:[YN]:[0-9]:[0-9]$//g' $raw/modified_cutadapt/$read1decomp > $raw/modified_cutadapt/read1_mod.fastq\n",
    "    !sed 's/\\ [0-9]:[YN]:[0-9]:[0-9]$//g' $raw/modified_cutadapt/$read2decomp > $raw/modified_cutadapt/read2_mod.fastq\n",
    "    !sed 's/\\ [0-9]:[YN]:[0-9]:[0-9]$//g' $raw/modified_cutadapt/$index1decomp > $raw/modified_cutadapt/index1_mod.fastq\n",
    "    !sed 's/\\ [0-9]:[YN]:[0-9]:[0-9]$//g' $raw/modified_cutadapt/$index2decomp > $raw/modified_cutadapt/index2_mod.fastq\n",
    "    \n",
    "    # Delete file copies\n",
    "    !rm $raw/modified_cutadapt/$read1decomp\n",
    "    !rm $raw/modified_cutadapt/$read2decomp\n",
    "    !rm $raw/modified_cutadapt/$index1decomp\n",
    "    !rm $raw/modified_cutadapt/$index2decomp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Remove primer from sequences\n",
    "\n",
    "There may still be portions of the primers left in the read sequences that need to be removed. Use cutadapt to remove those portions. Read1 will have the reverse complement of the reverse primer and read2 will have the reverse complement of the forward primer in some sequences on the 3' end.\n",
    "\n",
    "You will get a warning that the adapter is preceded by \"A\" or \"G\" extremely often. These are the link sequences in the primer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is cutadapt 3.4 with Python 3.8.8\n",
      "Command line parameters: -a ATTAGAWACCCBDGTAGTCC -o /home/backup_files/raw_reads/SFA2.cassi.2021/nano_v2/modified_cutadapt/read1_noprimer.fastq /home/backup_files/raw_reads/SFA2.cassi.2021/nano_v2/modified_cutadapt/read1_mod.fastq\n",
      "Processing reads on 1 core in single-end mode ...\n",
      "[    8<------] 00:00:09       788,290 reads  @     11.9 µs/read;   5.04 M reads/minute\n",
      "Finished in 9.38 s (12 µs/read; 5.04 M reads/minute).\n",
      "\n",
      "=== Summary ===\n",
      "\n",
      "Total reads processed:                 788,290\n",
      "Reads with adapters:                   256,673 (32.6%)\n",
      "Reads written (passing filters):       788,290 (100.0%)\n",
      "\n",
      "Total basepairs processed:   197,860,790 bp\n",
      "Total written (filtered):    191,248,531 bp (96.7%)\n",
      "\n",
      "=== Adapter 1 ===\n",
      "\n",
      "Sequence: ATTAGAWACCCBDGTAGTCC; Type: regular 3'; Length: 20; Trimmed: 256673 times\n",
      "\n",
      "No. of allowed errors:\n",
      "1-9 bp: 0; 10-19 bp: 1; 20 bp: 2\n",
      "\n",
      "Bases preceding removed adapters:\n",
      "  A: 0.7%\n",
      "  C: 1.0%\n",
      "  G: 97.4%\n",
      "  T: 0.9%\n",
      "  none/other: 0.0%\n",
      "WARNING:\n",
      "    The adapter is preceded by \"G\" extremely often.\n",
      "    The provided adapter sequence could be incomplete at its 5' end.\n",
      "\n",
      "Overview of removed sequences\n",
      "length\tcount\texpect\tmax.err\terror counts\n",
      "3\t3436\t12317.0\t0\t3436\n",
      "4\t922\t3079.3\t0\t922\n",
      "5\t202\t769.8\t0\t202\n",
      "6\t117\t192.5\t0\t117\n",
      "7\t13\t48.1\t0\t13\n",
      "8\t11\t12.0\t0\t11\n",
      "9\t19\t3.0\t0\t0 19\n",
      "11\t1\t0.2\t1\t0 1\n",
      "17\t2\t0.0\t1\t2\n",
      "19\t1\t0.0\t1\t1\n",
      "21\t4\t0.0\t2\t4\n",
      "22\t442\t0.0\t2\t369 38 35\n",
      "23\t112364\t0.0\t2\t102771 6269 3324\n",
      "24\t4427\t0.0\t2\t3997 278 152\n",
      "25\t282\t0.0\t2\t255 18 9\n",
      "26\t112\t0.0\t2\t99 8 5\n",
      "27\t30625\t0.0\t2\t27577 1962 1086\n",
      "28\t70219\t0.0\t2\t63739 4173 2307\n",
      "29\t1281\t0.0\t2\t1107 114 60\n",
      "30\t30186\t0.0\t2\t26928 2120 1138\n",
      "31\t195\t0.0\t2\t160 18 17\n",
      "32\t39\t0.0\t2\t30 2 7\n",
      "33\t3\t0.0\t2\t3\n",
      "36\t3\t0.0\t2\t3\n",
      "37\t6\t0.0\t2\t5 1\n",
      "38\t2\t0.0\t2\t1 0 1\n",
      "41\t1\t0.0\t2\t1\n",
      "42\t5\t0.0\t2\t1 3 1\n",
      "43\t1\t0.0\t2\t0 0 1\n",
      "45\t1\t0.0\t2\t1\n",
      "46\t1\t0.0\t2\t0 0 1\n",
      "47\t1322\t0.0\t2\t1237 56 29\n",
      "48\t25\t0.0\t2\t24 0 1\n",
      "49\t1\t0.0\t2\t1\n",
      "50\t1\t0.0\t2\t1\n",
      "52\t6\t0.0\t2\t2 4\n",
      "53\t1\t0.0\t2\t1\n",
      "63\t15\t0.0\t2\t14 1\n",
      "65\t1\t0.0\t2\t1\n",
      "70\t1\t0.0\t2\t1\n",
      "71\t3\t0.0\t2\t0 0 3\n",
      "72\t1\t0.0\t2\t0 1\n",
      "73\t8\t0.0\t2\t1 3 4\n",
      "74\t3\t0.0\t2\t1 2\n",
      "76\t1\t0.0\t2\t1\n",
      "77\t2\t0.0\t2\t0 1 1\n",
      "81\t1\t0.0\t2\t1\n",
      "83\t3\t0.0\t2\t3\n",
      "87\t1\t0.0\t2\t0 1\n",
      "94\t1\t0.0\t2\t1\n",
      "95\t1\t0.0\t2\t1\n",
      "104\t1\t0.0\t2\t1\n",
      "105\t1\t0.0\t2\t0 0 1\n",
      "106\t4\t0.0\t2\t3 0 1\n",
      "108\t1\t0.0\t2\t1\n",
      "115\t1\t0.0\t2\t1\n",
      "121\t1\t0.0\t2\t0 1\n",
      "132\t2\t0.0\t2\t0 2\n",
      "140\t2\t0.0\t2\t0 0 2\n",
      "144\t1\t0.0\t2\t1\n",
      "145\t5\t0.0\t2\t4 0 1\n",
      "152\t1\t0.0\t2\t0 0 1\n",
      "159\t1\t0.0\t2\t1\n",
      "160\t2\t0.0\t2\t0 2\n",
      "163\t1\t0.0\t2\t0 1\n",
      "166\t1\t0.0\t2\t0 0 1\n",
      "167\t2\t0.0\t2\t0 0 2\n",
      "173\t1\t0.0\t2\t1\n",
      "175\t8\t0.0\t2\t5 3\n",
      "180\t1\t0.0\t2\t0 1\n",
      "181\t1\t0.0\t2\t0 1\n",
      "182\t1\t0.0\t2\t1\n",
      "184\t3\t0.0\t2\t0 2 1\n",
      "185\t1\t0.0\t2\t1\n",
      "194\t2\t0.0\t2\t0 1 1\n",
      "197\t1\t0.0\t2\t0 1\n",
      "202\t1\t0.0\t2\t0 1\n",
      "206\t4\t0.0\t2\t0 0 4\n",
      "208\t9\t0.0\t2\t9\n",
      "209\t7\t0.0\t2\t0 6 1\n",
      "210\t2\t0.0\t2\t1 0 1\n",
      "211\t92\t0.0\t2\t84 6 2\n",
      "212\t22\t0.0\t2\t20 1 1\n",
      "213\t2\t0.0\t2\t2\n",
      "216\t69\t0.0\t2\t1 63 5\n",
      "219\t3\t0.0\t2\t1 1 1\n",
      "220\t2\t0.0\t2\t1 0 1\n",
      "223\t2\t0.0\t2\t0 0 2\n",
      "224\t1\t0.0\t2\t1\n",
      "225\t1\t0.0\t2\t0 1\n",
      "226\t1\t0.0\t2\t0 0 1\n",
      "229\t2\t0.0\t2\t2\n",
      "231\t2\t0.0\t2\t2\n",
      "236\t15\t0.0\t2\t4 8 3\n",
      "237\t2\t0.0\t2\t1 1\n",
      "238\t4\t0.0\t2\t4\n",
      "240\t1\t0.0\t2\t1\n",
      "241\t2\t0.0\t2\t1 1\n",
      "243\t14\t0.0\t2\t10 2 2\n",
      "244\t4\t0.0\t2\t4\n",
      "248\t3\t0.0\t2\t0 1 2\n",
      "249\t6\t0.0\t2\t1 0 5\n",
      "250\t11\t0.0\t2\t8 1 2\n",
      "251\t22\t0.0\t2\t5 14 3\n",
      "\n",
      "\n",
      "WARNING:\n",
      "    One or more of your adapter sequences may be incomplete.\n",
      "    Please see the detailed output above.\n",
      "This is cutadapt 3.4 with Python 3.8.8\n",
      "Command line parameters: -a TTACCGCGGCKGCTGGCAC -o /home/backup_files/raw_reads/SFA2.cassi.2021/nano_v2/modified_cutadapt/read2_noprimer.fastq /home/backup_files/raw_reads/SFA2.cassi.2021/nano_v2/modified_cutadapt/read2_mod.fastq\n",
      "Processing reads on 1 core in single-end mode ...\n",
      "[   8=-------] 00:00:07       788,290 reads  @      9.3 µs/read;   6.45 M reads/minute\n",
      "Finished in 7.33 s (9 µs/read; 6.45 M reads/minute).\n",
      "\n",
      "=== Summary ===\n",
      "\n",
      "Total reads processed:                 788,290\n",
      "Reads with adapters:                   240,464 (30.5%)\n",
      "Reads written (passing filters):       788,290 (100.0%)\n",
      "\n",
      "Total basepairs processed:   197,860,790 bp\n",
      "Total written (filtered):    191,862,657 bp (97.0%)\n",
      "\n",
      "=== Adapter 1 ===\n",
      "\n",
      "Sequence: TTACCGCGGCKGCTGGCAC; Type: regular 3'; Length: 19; Trimmed: 240464 times\n",
      "\n",
      "No. of allowed errors:\n",
      "1-9 bp: 0; 10-19 bp: 1\n",
      "\n",
      "Bases preceding removed adapters:\n",
      "  A: 96.7%\n",
      "  C: 1.9%\n",
      "  G: 0.4%\n",
      "  T: 1.0%\n",
      "  none/other: 0.0%\n",
      "WARNING:\n",
      "    The adapter is preceded by \"A\" extremely often.\n",
      "    The provided adapter sequence could be incomplete at its 5' end.\n",
      "\n",
      "Overview of removed sequences\n",
      "length\tcount\texpect\tmax.err\terror counts\n",
      "3\t3230\t12317.0\t0\t3230\n",
      "4\t3668\t3079.3\t0\t3668\n",
      "5\t5493\t769.8\t0\t5493\n",
      "6\t39\t192.5\t0\t39\n",
      "7\t55\t48.1\t0\t55\n",
      "11\t1\t0.2\t1\t0 1\n",
      "12\t1\t0.0\t1\t0 1\n",
      "17\t2\t0.0\t1\t2\n",
      "19\t1\t0.0\t1\t1\n",
      "21\t4\t0.0\t1\t4\n",
      "22\t382\t0.0\t1\t335 47\n",
      "23\t101069\t0.0\t1\t92491 8578\n",
      "24\t3926\t0.0\t1\t966 2960\n",
      "25\t244\t0.0\t1\t211 33\n",
      "26\t109\t0.0\t1\t84 25\n",
      "27\t28243\t0.0\t1\t26025 2218\n",
      "28\t63853\t0.0\t1\t58713 5140\n",
      "29\t1123\t0.0\t1\t1020 103\n",
      "30\t27344\t0.0\t1\t25162 2182\n",
      "31\t160\t0.0\t1\t147 13\n",
      "32\t29\t0.0\t1\t25 4\n",
      "33\t2\t0.0\t1\t2\n",
      "36\t3\t0.0\t1\t2 1\n",
      "37\t5\t0.0\t1\t4 1\n",
      "38\t1\t0.0\t1\t1\n",
      "41\t1\t0.0\t1\t1\n",
      "42\t4\t0.0\t1\t2 2\n",
      "45\t1\t0.0\t1\t1\n",
      "47\t1236\t0.0\t1\t1149 87\n",
      "48\t23\t0.0\t1\t22 1\n",
      "49\t1\t0.0\t1\t1\n",
      "50\t1\t0.0\t1\t1\n",
      "52\t2\t0.0\t1\t2\n",
      "53\t1\t0.0\t1\t1\n",
      "58\t1\t0.0\t1\t0 1\n",
      "63\t15\t0.0\t1\t15\n",
      "65\t1\t0.0\t1\t0 1\n",
      "73\t1\t0.0\t1\t1\n",
      "74\t4\t0.0\t1\t3 1\n",
      "81\t1\t0.0\t1\t1\n",
      "83\t3\t0.0\t1\t3\n",
      "84\t4\t0.0\t1\t0 4\n",
      "87\t1\t0.0\t1\t0 1\n",
      "94\t1\t0.0\t1\t1\n",
      "95\t1\t0.0\t1\t1\n",
      "97\t1\t0.0\t1\t0 1\n",
      "104\t1\t0.0\t1\t1\n",
      "106\t3\t0.0\t1\t0 3\n",
      "108\t1\t0.0\t1\t1\n",
      "115\t1\t0.0\t1\t1\n",
      "132\t1\t0.0\t1\t0 1\n",
      "144\t1\t0.0\t1\t1\n",
      "145\t2\t0.0\t1\t0 2\n",
      "159\t1\t0.0\t1\t1\n",
      "166\t1\t0.0\t1\t1\n",
      "173\t1\t0.0\t1\t1\n",
      "175\t6\t0.0\t1\t5 1\n",
      "180\t1\t0.0\t1\t1\n",
      "182\t3\t0.0\t1\t0 3\n",
      "185\t1\t0.0\t1\t0 1\n",
      "195\t1\t0.0\t1\t1\n",
      "202\t1\t0.0\t1\t0 1\n",
      "209\t5\t0.0\t1\t0 5\n",
      "211\t17\t0.0\t1\t16 1\n",
      "212\t1\t0.0\t1\t1\n",
      "216\t51\t0.0\t1\t43 8\n",
      "219\t2\t0.0\t1\t2\n",
      "220\t1\t0.0\t1\t1\n",
      "229\t1\t0.0\t1\t1\n",
      "230\t1\t0.0\t1\t0 1\n",
      "231\t2\t0.0\t1\t1 1\n",
      "236\t18\t0.0\t1\t0 18\n",
      "237\t2\t0.0\t1\t0 2\n",
      "238\t4\t0.0\t1\t3 1\n",
      "240\t1\t0.0\t1\t1\n",
      "241\t2\t0.0\t1\t2\n",
      "243\t10\t0.0\t1\t9 1\n",
      "244\t3\t0.0\t1\t3\n",
      "248\t1\t0.0\t1\t1\n",
      "249\t1\t0.0\t1\t1\n",
      "250\t6\t0.0\t1\t4 2\n",
      "251\t18\t0.0\t1\t4 14\n",
      "\n",
      "\n",
      "WARNING:\n",
      "    One or more of your adapter sequences may be incomplete.\n",
      "    Please see the detailed output above.\n"
     ]
    }
   ],
   "source": [
    "for library in libraries:\n",
    "    raw = library[2]\n",
    "    read1 = library[3]\n",
    "    read2 = library[4]\n",
    "    \n",
    "    !cutadapt -a ATTAGAWACCCBDGTAGTCC -o $raw/modified_cutadapt/read1_noprimer.fastq $raw/modified_cutadapt/read1_mod.fastq\n",
    "    !cutadapt -a TTACCGCGGCKGCTGGCAC -o $raw/modified_cutadapt/read2_noprimer.fastq $raw/modified_cutadapt/read2_mod.fastq\n",
    "    \n",
    "    # Delete unneeded intermediate files\n",
    "    !rm $raw/modified_cutadapt/read*_mod.fastq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Filter short reads\n",
    "\n",
    "Remove sequences with from primer-removed data with less than 100 bp from all files (too short)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for library in libraries:\n",
    "    raw = library[2]\n",
    "    os.system(' '.join([\n",
    "        \"python /home/cassi/scripts/qiime2_filter_shortreads.py\",\n",
    "        raw+\"/modified_cutadapt/\"\n",
    "    ]))\n",
    "    \n",
    "    # Remove unneeded intermediate files\n",
    "    !rm $raw/modified_cutadapt/*_noprimer.fastq\n",
    "    !rm $raw/modified_cutadapt/index*_mod.fastq\n",
    "    \n",
    "    # Recompress modified read files\n",
    "    !pigz $raw/modified_cutadapt/read*_filtered.fastq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: Concatenate barcodes\n",
    "\n",
    "This step calls a custom script, \"concatenate_barcodes_qiime2.py\". The script must be shuttled to the command line instead of run directly in jupyter notebooks because jupyter has memory issues that truncates the barcodes file without an error (I think).\n",
    "\n",
    "This script requires your index1 and index2 files to be named index1_mod.fastq and index2_mod.fastq and be located in a directory within the raw read directory called 'modified'. This should have been taken care of in earlier steps in this pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for library in libraries:\n",
    "    raw = library[2]\n",
    "    \n",
    "    os.system(' '.join([\n",
    "        \"python /home/cassi/scripts/qiime2_concatenate_barcodes.py\",\n",
    "        raw+\"/modified_cutadapt\"]))\n",
    "  \n",
    "    # Recompress modified index files and newly created barcodes.fastq file\n",
    "    !pigz $raw/modified_cutadapt/*.fastq   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6: Move raw data to library directories\n",
    "\n",
    "Creates intermediate directory in library directory. All subsequent files except for the final files will be placed there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for library in libraries:\n",
    "    proc = library[1]\n",
    "    raw = library[2]\n",
    "    \n",
    "    # Create output directory if it doesn't exist already\n",
    "    if not os.path.isdir(os.path.join(proc, \"intermediate\")):\n",
    "        !mkdir $proc/intermediate\n",
    "    \n",
    "    # Create a symbolic link to the read data\n",
    "    # QIIME2 import requires a directory containing files named: forward.fastq.gz, reverse.fastq.gz and barcodes.fastq.gz \n",
    "    !ln -s $raw/modified_cutadapt/read1_filtered.fastq.gz $proc/intermediate/forward.fastq.gz\n",
    "    !ln -s $raw/modified_cutadapt/read2_filtered.fastq.gz $proc/intermediate/reverse.fastq.gz\n",
    "    \n",
    "    # Move concatenated barcodes to project directory\n",
    "    !cp $raw/modified_cutadapt/barcodes.fastq.gz $proc/intermediate/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 7: Import into QIIME2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for library in libraries:\n",
    "    name = library[0]\n",
    "    proc = library[1]\n",
    "    \n",
    "    os.system(' '.join([\n",
    "        \"qiime tools import\",\n",
    "        \"--type EMPPairedEndSequences\",\n",
    "        \"--input-path \"+proc+\"/intermediate\",\n",
    "        \"--output-path \"+proc+\"/intermediate/\"+name+\".qza\"\n",
    "    ]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 8: Demultiplex\n",
    "\n",
    "The barcode you supply to QIIME is now a concatenation of your forward and reverse barcode. Your 'forward' barcode is actually the reverse complement of your reverse barcode and the 'reverse' is your forward barcode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for library in libraries:\n",
    "    name = library[0]\n",
    "    proc = library[1]\n",
    "    metadata = library[7]\n",
    "    \n",
    "    os.system(' '.join([\n",
    "        \"qiime demux emp-paired\",\n",
    "        \"--m-barcodes-file \"+proc+\"/\"+metadata,\n",
    "        \"--m-barcodes-column BarcodeSequence\",\n",
    "        \"--p-no-golay-error-correction\",\n",
    "        \"--i-seqs \"+proc+\"/intermediate/\"+name+\".qza\",\n",
    "        \"--o-per-sample-sequences \"+proc+\"/intermediate/\"+name+\".demux\",\n",
    "        \"--o-error-correction-details \"+proc+\"/intermediate/\"+name+\".demux-details.qza\"\n",
    "    ]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 9: Visualize quality scores\n",
    "\n",
    "Drop output from below command into https://view.qiime2.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for library in libraries:\n",
    "    name = library[0]\n",
    "    proc = library[1]\n",
    "    \n",
    "    os.system(' '.join([\n",
    "        \"qiime demux summarize\",\n",
    "        \"--i-data \"+proc+\"/intermediate/\"+name+\".demux.qza\",\n",
    "        \"--o-visualization \"+proc+\"/intermediate/\"+name+\".demux.qzv\"\n",
    "    ]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 10: Trimming parameters | USER INPUT REQUIRED\n",
    "\n",
    "Based on the quality scores of the bp along the reads, choose trim and truncate values for the forward and reverse reads. Trim refers to the start of a sequence and truncate the total length (i.e. number of bases to remove from end).\n",
    "\n",
    "All trimming parameters must be the same for datasets that will be directly compared to one-another because ASVs are determined by sequence length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Input your trimming parameters into a python dictionary for all libraries\n",
    "# trim_dict = {\"LibraryName1\":[trim_forward, truncate_forward, trim_reverse, truncate_reverse],\n",
    "#              \"LibraryName2\":[trim_forward, truncate_forward, trim_reverse, truncate_reverse],\n",
    "#               etc...}\n",
    "\n",
    "# The example in the Atacama Desert Tutorial trims 13 bp from the start of each read and does not remove any bases from the end of the 150 bp reads:\n",
    "#  --p-trim-left-f 13 \\  \n",
    "#  --p-trim-left-r 13 \\\n",
    "#  --p-trunc-len-f 150 \\\n",
    "#  --p-trunc-len-r 150\n",
    "\n",
    "trim_dict = {\"SFA2_nano2_cutadapt\":[10,240,10,240]} # beautiful quality!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 11: Trim, denoise and join (aka 'merge') reads using DADA2\n",
    "\n",
    "See the [QIIME2 dada2 denoise-paired documentation](https://docs.qiime2.org/2021.8/plugins/available/dada2/denoise-paired/) for the default parameters used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for library in libraries:\n",
    "    name = library[0]\n",
    "    proc = library[1]\n",
    "    \n",
    "    os.system(' '.join([\n",
    "        \"qiime dada2 denoise-paired\",\n",
    "        \"--i-demultiplexed-seqs \"+proc+\"/intermediate/\"+name+\".demux.qza\",\n",
    "        \"--o-table \"+proc+\"/intermediate/\"+name+\".table.qza\",\n",
    "        \"--o-representative-sequences \"+proc+\"/intermediate/\"+name+\".rep-seqs.qza\",\n",
    "        \"--o-denoising-stats \"+proc+\"/intermediate/\"+name+\".denoising-stats.qza\",\n",
    "        \"--p-trim-left-f \"+str(trim_dict[name][0]),\n",
    "        \"--p-trim-left-r \"+str(trim_dict[name][2]),\n",
    "        \"--p-trunc-len-f \"+str(trim_dict[name][1]),\n",
    "        \"--p-trunc-len-r \"+str(trim_dict[name][3]),\n",
    "        \"--p-n-threads\",\n",
    "        str(processors)\n",
    "    ]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 12: Create summary of ASVs\n",
    "\n",
    "Drop outputs from below command into https://view.qiime2.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for library in libraries:\n",
    "    name = library[0]\n",
    "    proc = library[1]\n",
    "    metadata = library[7]\n",
    "    \n",
    "    os.system(' '.join([\n",
    "        \"qiime feature-table summarize\",\n",
    "        \"--i-table \"+proc+\"/intermediate/\"+name+\".table.qza\",\n",
    "        \"--o-visualization \"+proc+\"/intermediate/\"+name+\".table.qzv\",\n",
    "        \"--m-sample-metadata-file \"+proc+\"/\"+metadata\n",
    "    ]))\n",
    "\n",
    "    os.system(' '.join([\n",
    "        \"qiime feature-table tabulate-seqs\",\n",
    "        \"--i-data \"+proc+\"/intermediate/\"+name+\".rep-seqs.qza\",\n",
    "        \"--o-visualization \"+proc+\"/intermediate/\"+name+\".rep-seqs.qzv\"\n",
    "    ])) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 13: Classify sequences\n",
    "\n",
    "Different QIIME2 versions can conflict with certain classifier database versions. This section will likely need to be updated. Download the latest classifiers here: https://docs.qiime2.org/2021.4/data-resources/\n",
    "\n",
    "* Using SILVA v138 pre-built classifier trained on scikit learn 0.24.1.\n",
    "\n",
    "View output in https://view.qiime2.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use classifier for chosen database\n",
    "try:\n",
    "    if db == \"GreenGenes\":\n",
    "        classifier_db = \"/home/db/GreenGenes/qiime2_13.8.99_515.806_nb.classifier.qza\" # out of date\n",
    "    else:\n",
    "        classifier_db = \"~/databases/silva/silva-138-99-515-806-nb-classifier.qza\"\n",
    "except:\n",
    "        classifier_db = \"~/databases/silva/silva-138-99-515-806-nb-classifier.qza\"\n",
    "        \n",
    "for library in libraries:\n",
    "    name = library[0]\n",
    "    proc = library[1]\n",
    "    metadata = library[7]\n",
    "    domain = library[8]\n",
    "\n",
    "    # Classify\n",
    "    if domain == 'bacteria':\n",
    "        os.system(' '.join([\n",
    "            \"qiime feature-classifier classify-sklearn\",\n",
    "            \"--i-classifier\",\n",
    "            classifier_db,\n",
    "            \"--i-reads \"+proc+\"/intermediate/\"+name+\".rep-seqs.qza\",\n",
    "            \"--o-classification \"+proc+\"/intermediate/\"+name+\".taxonomy.qza\",\n",
    "            \"--p-n-jobs\",\n",
    "            str(processors)\n",
    "        ]))\n",
    "\n",
    "    if domain == 'fungi':\n",
    "        os.system(' '.join([\n",
    "            \"qiime feature-classifier classify-sklearn\",\n",
    "            \"--i-classifier /home/db/UNITE/qiime2_unite_ver7.99_20.11.2016_classifier.qza\", # out of date\n",
    "            \"--i-reads \"+proc+\"/intermediate/\"+name+\".rep-seqs.qza\",\n",
    "            \"--o-classification \"+proc+\"/intermediate/\"+name+\".taxonomy.qza\",\n",
    "            \"--p-n-jobs\",\n",
    "            str(processors)\n",
    "        ]))\n",
    "\n",
    "    # Output summary\n",
    "    os.system(' '.join([\n",
    "        \"qiime metadata tabulate\",\n",
    "        \"--m-input-file \"+proc+\"/intermediate/\"+name+\".taxonomy.qza\",\n",
    "        \"--o-visualization \"+proc+\"/intermediate/\"+name+\".taxonomy-summary.qzv\"\n",
    "    ])) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 14: Generate representative sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bacteria\n",
    "for library in libraries:\n",
    "    name = library[0]\n",
    "    proc = library[1]\n",
    "    domain = library[8]\n",
    "    \n",
    "    # Create representative sequences file\n",
    "    repseqsbac = []\n",
    "    \n",
    "    if domain == \"bacteria\":\n",
    "        repseqsbac.append(\"--i-data \" + os.path.join(proc, \"intermediate\", name+\".rep-seqs.qza\"))\n",
    "\n",
    "# Create tree proc\n",
    "if not os.path.isdir(os.path.join(project, \"tree\")):\n",
    "    !mkdir $project/tree\n",
    "        \n",
    "# Merge rep sequences from all bacterial libraries for tree\n",
    "os.system(' '.join([\n",
    "    \"qiime feature-table merge-seqs\",\n",
    "    \" \".join(repseqsbac),\n",
    "    \"--o-merged-data \"+project+\"/tree/\"+treename+\".rep-seqs-merged.qza\"\n",
    "]))\n",
    "\n",
    "# Fungi\n",
    "for library in libraries:\n",
    "    name = library[0]\n",
    "    proc = library[1]\n",
    "    domain = library[8]\n",
    "    \n",
    "    # Create representative sequences file\n",
    "    repseqsfung = []\n",
    "    \n",
    "    if domain == \"fungi\":\n",
    "        repseqsfung.append(\"--i-data \" + os.path.join(proc, \"intermediate\", name+\".rep-seqs.qza\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 15: Make phylogenetic tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "if domain == \"bacteria\":\n",
    "    # Generate alignment with MAFFT\n",
    "    os.system(' '.join([\n",
    "        \"qiime alignment mafft\",\n",
    "        \"--i-sequences \"+project+\"/tree/\"+treename+\".rep-seqs-merged.qza\",\n",
    "        \"--o-alignment \"+project+\"/tree/\"+treename+\".rep-seqs-merged-aligned.qza\",\n",
    "        \"--p-n-threads\",\n",
    "        str(processors)\n",
    "    ]))\n",
    "\n",
    "    # Mask hypervariable regions in alignment\n",
    "    os.system(' '.join([\n",
    "        \"qiime alignment mask\",\n",
    "        \"--i-alignment \"+project+\"/tree/\"+treename+\".rep-seqs-merged-aligned.qza\",\n",
    "        \"--o-masked-alignment \"+project+\"/tree/\"+treename+\".rep-seqs-merged-aligned-masked.qza\",\n",
    "    ]))\n",
    "\n",
    "    # Generate tree with FastTree\n",
    "    os.system(' '.join([\n",
    "        \"qiime phylogeny fasttree\",\n",
    "        \"--i-alignment \"+project+\"/tree/\"+treename+\".rep-seqs-merged-aligned-masked.qza\",\n",
    "        \"--o-tree \"+project+\"/tree/\"+treename+\".tree-unrooted.qza\",\n",
    "        \"--p-n-threads\",\n",
    "        str(processors)\n",
    "    ]))\n",
    "\n",
    "    # Root the tree\n",
    "    os.system(' '.join([\n",
    "        \"qiime phylogeny midpoint-root\",\n",
    "        \"--i-tree \"+project+\"/tree/\"+treename+\".tree-unrooted.qza\",\n",
    "        \"--o-rooted-tree \"+project+\"/tree/\"+treename+\".tree-rooted.qza\"\n",
    "    ]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 16: Reformat taxonomy\n",
    "\n",
    "Define function to tidy the taxonomy and make it compatible with phyloseq."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_taxonomy(tax_dirty, min_support):\n",
    "    output = open(re.sub(\".tsv\",\"-fixed.tsv\",tax_dirty), \"w\")\n",
    "    \n",
    "    full_rank_length = 7\n",
    "    output.write(\"\\t\".join([\"ASV\",\"Domain\",\"Phylum\",\"Class\",\"Order\",\"Family\",\"Genus\",\"Species\"])+\"\\n\")\n",
    "\n",
    "    with open(tax_dirty, \"r\") as f:\n",
    "        next(f)\n",
    "\n",
    "        for line in f:\n",
    "                line = line.strip()\n",
    "                line = line.split(\"\\t\")\n",
    "\n",
    "                read_id = line[0]\n",
    "                tax_string = line[1]\n",
    "                \n",
    "                ## Remove taxonomy prefixes and underscores (only coded for Silva classifications so far)\n",
    "                if db == \"Silva\":\n",
    "                    tax_string = re.sub(\"[a-z]__\", \"\", tax_string)\n",
    "                    tax_string = re.sub(\"_\", \" \", tax_string)\n",
    "\n",
    "                # Split full rank into ranks\n",
    "                full_rank = tax_string.split(\";\")\n",
    "\n",
    "                ## Identify the lowest classified taxonomic rank\n",
    "                # Account for cases when a taxonomic rank contains an empty space (common in GreenGenes output)\n",
    "                last_classified = full_rank[len(full_rank)-1]            \n",
    "\n",
    "                count = 1\n",
    "                while last_classified == \" \":\n",
    "                    last_classified = full_rank[len(full_rank)-count]\n",
    "                    count = count + 1\n",
    "\n",
    "                # Annotate the last classified as 'putative' if it does not meet the minimum support criteria\n",
    "                if float(line[2]) < float(min_support):\n",
    "                        full_rank[full_rank.index(last_classified)] = \"putative \"+last_classified\n",
    "                        last_classified = \"putative \"+last_classified\n",
    "\n",
    "                # Add in columns containing unclassified taxonomic information\n",
    "                for n in range(full_rank.index(last_classified)+1, full_rank_length, 1):               \n",
    "                    try:\n",
    "                        full_rank[n] = \"unclassified \"+last_classified\n",
    "                    except:\n",
    "                        full_rank.append(\"unclassified \"+last_classified)\n",
    "\n",
    "                # Write taxonomy to file\n",
    "                output.write(read_id+\"\\t\"+'\\t'.join(full_rank)+\"\\n\")\n",
    "    return()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 17: Export from QIIME2\n",
    "\n",
    "All final files will be placed in 'final' directory in library directories. Final tree will be in a 'tree' directory in the project directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for library in libraries:\n",
    "    name = library[0]\n",
    "    proc = library[1]\n",
    "    metadata = library[7]\n",
    "\n",
    "    # Final output paths\n",
    "    fasta_final = proc+\"/final/\"+name+\".rep-seqs-final.fasta\"\n",
    "    tax_final= proc+\"/final/\"+name+\".taxonomy-final.tsv\"\n",
    "    count_final = proc+\"/final/\"+name+\".counts-final.biom\"\n",
    "    \n",
    "    # Make final data directories\n",
    "    if not os.path.isdir(os.path.join(proc, \"final\")):\n",
    "        !mkdir $proc/final\n",
    "        \n",
    "    # Export ASV table\n",
    "    os.system(' '.join([\n",
    "        \"qiime tools export\",\n",
    "        \"--input-path \"+proc+\"/intermediate/\"+name+\".table.qza\",\n",
    "        \"--output-path \"+proc+\"/intermediate/\"\n",
    "    ]))\n",
    "\n",
    "    # Export taxonomic classifications\n",
    "    os.system(' '.join([\n",
    "        \"qiime tools export\",\n",
    "        \"--input-path \"+proc+\"/intermediate/\"+name+\".taxonomy.qza\",\n",
    "        \"--output-path \"+proc+\"/intermediate/\"\n",
    "    ]))\n",
    "    \n",
    "    # Reformat classifications  \n",
    "    format_taxonomy(proc+\"/intermediate/taxonomy.tsv\", min_support)\n",
    "\n",
    "    # Export representative sequences\n",
    "    os.system(' '.join([\n",
    "        \"qiime tools export\",\n",
    "        \"--input-path \"+proc+\"/intermediate/\"+name+\".rep-seqs.qza\",\n",
    "        \"--output-path \"+proc+\"/intermediate/\"\n",
    "    ]))\n",
    "    \n",
    "    # Rename exported files and move to final directory\n",
    "    !mv $proc/intermediate/dna-sequences.fasta $fasta_final\n",
    "    !mv $proc/intermediate/feature-table.biom $count_final\n",
    "    !mv $proc/intermediate/taxonomy-fixed.tsv $tax_final\n",
    "    \n",
    "    # Convert count.biom to .tsv format and remove header line\n",
    "    tmp_tsv = re.sub(name+\".counts-final.biom\", \"tmp.tsv\", count_final)\n",
    "    count_tsv = re.sub(\".biom\", \".tsv\", count_final)\n",
    "    !biom convert -i $count_final -o $tmp_tsv --to-tsv\n",
    "    !tail -n +2 $tmp_tsv > $count_tsv\n",
    "    !rm $tmp_tsv\n",
    "    \n",
    "# Export tree\n",
    "os.system(' '.join([\n",
    "    \"qiime tools export\",\n",
    "    \"--input-path \"+project+\"/tree/\"+treename+\".tree-rooted.qza\",\n",
    "    \"--output-path \"+project+\"/tree/\"\n",
    "]))\n",
    "\n",
    "# Rename tree file\n",
    "tree_final = project+\"/tree/\"+treename+\".tree-final.nwk\"\n",
    "!mv $project/tree/\"tree.nwk\" $tree_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Done!"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "hide_input": true,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
