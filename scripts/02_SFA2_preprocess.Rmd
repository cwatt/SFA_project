---
title: "SFA2 - prerocessing"
author: "Cassandra Wattenburger"
date: "9/15/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(results = "show")
knitr::opts_chunk$set(message = FALSE)
```

```{r}
# Clear working directory, load in packages, generate package info
rm(list=ls())

library("tidyverse")
library("ape")
library("phyloseq")

sessionInfo()
```

### Import data

```{r}
# Rep 1
count_rep1 <- read_tsv(file="~/SFAgrowthrate/data_amplicon/SFA2_full/rep1/final/SFA2_rep1.counts-final.tsv")
tax_rep1 <- read_tsv(file="~/SFAgrowthrate/data_amplicon/SFA2_full/rep1/final/SFA2_rep1.taxonomy-final.tsv")

# Rep 2
count_rep2 <- read_tsv(file="~/SFAgrowthrate/data_amplicon/SFA2_full/rep2/final/SFA2_rep2.counts-final.tsv")
tax_rep2 <- read_tsv(file="~/SFAgrowthrate/data_amplicon/SFA2_full/rep2/final/SFA2_rep2.taxonomy-final.tsv")

# Rep 3
count_rep3 <- read_tsv(file="~/SFAgrowthrate/data_amplicon/SFA2_full/rep3/final/SFA2_rep3.counts-final.tsv")
tax_rep3 <- read_tsv(file="~/SFAgrowthrate/data_amplicon/SFA2_full/rep3/final/SFA2_rep3.taxonomy-final.tsv")

# Tree
tree <- read.tree(file="~/SFAgrowthrate/data_amplicon/SFA2_full/tree/SFA2_full.tree-final.nwk")

# Metadata
meta <- read_tsv(file = "~/SFAgrowthrate/data_amplicon/SFA2_full/SFA2_metadata.tsv")
```

Combine replicate data

```{r}
count <- full_join(count_rep1, count_rep2, by="ASV") %>%
  full_join(count_rep3, by="ASV")

tax <- full_join(tax_rep1, tax_rep2) %>%
  full_join(tax_rep3)
```

### Import into phyloseq

```{r}
# Reformat and import count table
count_matrix <- count %>%
  column_to_rownames(var="ASV") %>%
  rename_with(~ gsub("(.+)", "sa\\1", .x)) %>%
  as.matrix()

phy_count <- otu_table(count_matrix, taxa_are_rows=TRUE)

# Reformat and import taxonomy table
tax_matrix <- tax %>% 
  column_to_rownames(var="ASV") %>% 
  as.matrix()

phy_tax <- tax_table(tax_matrix)

# Metadata import
phy_meta <- sample_data(meta)

# Create phyloseq object
physeq <- phyloseq(phy_count, phy_tax, phy_meta, tree)

physeq
```

### Remove non-prokaryotic ASVs

Mitochondrial, chloroplast, protist, unknown domain sequences.

```{r}
physeq_remove_asvs <- taxa_names(subset_taxa(physeq, Class=="Chloroplast" | Family=="Mitochondria" |
                                          Domain=="Unassigned" | Domain=="putative Unassigned" |
                                          Domain=="putative Bacteria"))
physeq_all_asvs <- taxa_names(physeq)
physeq_keep_asvs <- physeq_all_asvs[!(physeq_all_asvs %in% physeq_remove_asvs)]
physeq2 <- prune_taxa(physeq_keep_asvs, physeq)

physeq2
```

### Sparcity filters

Keep only ASVs that occur in at least three samples.

```{r}
asvs_sparce_pass <- count %>%
  mutate(across(-ASV, ~if_else(.x > 0, 1, 0), {.cols})) %>%
  mutate(total = rowSums(.[-1])) %>%
  filter(total > 2) %>%
  .$ASV

physeq3 <- prune_taxa(asvs_sparce_pass, physeq2)

physeq3
```

### Read depth

```{r}
# Extract count and metadata from processed phyloseq object
count_processed <- data.frame(otu_table(physeq3))
meta_processed <- data.frame(sample_data(physeq3)) %>%
  select(-Sample) %>%
  rownames_to_column(var="Sample")

# Calculate read depth per sample
read_depth <- count_processed %>%
  rownames_to_column(var="ASV") %>%
  gather(Sample, count, -ASV) %>%
  spread(ASV, count) %>%
  mutate(total = rowSums(.[-1])) %>%
  select(Sample, total) %>%
  inner_join(meta_processed)
  
read_depth %>%
  mutate(Replicate = as_factor(Replicate)) %>%
  filter(Type != "pcr_control") %>%
  ggplot(aes(x=reorder(Sample, -total), y=total, fill=Replicate)) +
  geom_col() +
  labs(x="Sample", y="Reads") +
  theme_test()
```

### Identify samples to resequence

Based on combination of amount of internal standard, read depth, and ASV richness.

Build dataframe with spike-in, read depth, and ASV richness information.

```{r}
# Extract taxonomy table from phyloseq
tax_processed <- data.frame(tax_table(physeq3))

# Isolate Aquifex ASV
aquifex <- tax_processed %>%
  filter(Genus == "Aquifex") %>%
  rownames_to_column(var="ASV") %>%
  select(ASV) %>%
  .$ASV

aquifex
```

```{r}
# Aquifex reads
total_std <- count_processed %>%
  rownames_to_column(var="ASV") %>% 
  filter(ASV == "445e8681c3c1a735760e6c394f5f4d0a") %>% 
  select(-ASV) %>%
  gather(variable, value) %>% 
  rename(Sample = variable, std_count = value) %>% 
  full_join(read_depth, by="Sample")

# ASV richness
richness <- count_processed %>% 
  mutate(across(everything(), ~ if_else(.x > 0, 1, 0), {.cols})) %>%
  colSums() %>%
  data.frame() %>% 
  rownames_to_column(var="Sample")

# Combine
std_depth_rich <- inner_join(total_std, richness) %>% 
  select(c(Sample, Type:PCR_plate, read_depth=total, std_count, richness=`.`)) %>% 
  mutate(Replicate = as_factor(Replicate))

# Import DNA conc. data
#dna <- read_csv(file="~/SFAgrowthrate/data_picogreen/SFA2_dnaconc.csv")

# Combine and add DNA concentration data
#std_depth_rich <- full_join(total_std, richness) %>% 
#  
#  select(c(Sample, Type:PCR_plate, aquifex_count, total, richness = `.`)) %>% 
#  mutate(Replicate = as_factor(Replicate))
```

Evaluate

```{r}
std_depth_rich %>% 
  ggplot(aes(x=Day, y=std_count, color=Replicate)) +
  geom_point() +
  labs(y="Aquifex ASV reads") + 
  theme_test()

std_depth_rich %>% 
  ggplot(aes(x=Day, y=std_count, color=Replicate)) +
  geom_point() +
  geom_label(aes(label=Sample)) +
  labs(y="Aquifex ASV reads") + 
  theme_test()

# log
std_depth_rich %>% 
  ggplot(aes(x=Day, y=log(std_count), color=Replicate)) +
  geom_point() +
  geom_label(aes(label=Sample)) +
  labs(y="Aquifex ASV reads") + 
  theme_test()
```

Samples 383 outlier, want to resequence.

Samples with no Aquifex reads:

```{r}
samples_nostd <- std_depth_rich %>% 
  filter(std_count == 0) %>%
  .$Sample

samples_nostd
length(samples_nostd)
```

Samples with high read depth and low Aquifex reads:

* Indicates not enough spike-in, variability on low end likely higher and less reliable normalization

```{r}
std_depth_rich %>% 
  ggplot(aes(x=read_depth, y=log(std_count), color=Replicate)) +
  geom_point() +
  theme_test()
```

Nothing stands out on high end of read depth.

```{r}
std_depth_rich %>% 
  mutate(std_prop = std_count/read_depth) %>% 
  ggplot(aes(y=std_prop, x=Day, color=Replicate)) +
  geom_point() +
  theme_test()

# Zoom in
std_depth_rich %>% 
  mutate(std_prop = std_count/read_depth) %>% 
  ggplot(aes(y=std_prop, x=Day, color=Replicate)) +
  geom_point() +
  ylim(0, 0.005) +
  theme_test()
```

Suspect samples have a low proportion and count of the standard.

```{r}
std_depth_rich %>% 
  mutate(std_prop = std_count/read_depth) %>% 
  filter(std_count < 30 & std_count > 0)

std_depth_rich %>% 
  mutate(std_prop = std_count/read_depth) %>% 
  filter(std_prop < 0.001)

std_depth_rich %>% 
  mutate(std_prop = std_count/read_depth) %>% 
  filter(std_count < 30 & std_count > 0 & std_prop < 0.001)
```

Samples with low spike-in for resequencing:

```{r}
samples_lowstd <- std_depth_rich %>% 
  mutate(std_prop = std_count/read_depth) %>%
  filter(std_count < 30 & std_count > 0 & std_prop < 0.005) %>% 
  .$Sample

samples_lowstd
length(samples_lowstd)
```

Samples with low coverage may also benefit from resequencing.

Read depth coverage:

```{r}
std_depth_rich %>%
  mutate(Replicate = as_factor(Replicate)) %>% 
  ggplot(aes(x=Sample, y=read_depth, color=Replicate)) +
  geom_point() +
  labs(y="Read depth") +
  theme_test()
```

Sample richness:

```{r}
std_depth_rich %>%
  ggplot(aes(x=Sample, y=richness)) +
  geom_point() +
  labs(y="Total ASVs") +
  theme_test()
```

Read depth vs richness:

```{r}
std_depth_rich %>%
  ggplot(aes(x=read_depth, y=richness, color=Replicate)) +
  geom_point() +
  labs(y="Total ASVs", x="Read depth") +
  theme_test()
```

Replicate one has better read coverage and has higher richness for many samples as a result. Rarefying would help with that.

Difference in richness between samples above or below 5000 read depth:

```{r}
lowdepth_rich <- std_depth_rich %>%
  filter(read_depth < 5000) %>%
  filter(Replicate != 1) # remove outlying replicate

highdepth_rich <- std_depth_rich %>%
  filter(read_depth > 5000) %>%
  filter(Replicate != 1) # remove outlying replicate

mean(lowdepth_rich$richness)
mean(highdepth_rich$richness)
```

""" 2500 read depth:

```{r}
lowdepth_rich <- std_depth_rich %>%
  filter(read_depth < 2500) %>%
  filter(Replicate != 1) # remove outlying replicate

highdepth_rich <- std_depth_rich %>%
  filter(read_depth > 2500) %>%
  filter(Replicate != 1) # remove outlying replicate

mean(lowdepth_rich$richness)
mean(highdepth_rich$richness)
```

""" 2000 read depth:

```{r}
lowdepth_rich <- std_depth_rich %>%
  filter(read_depth < 2000) %>%
  filter(Replicate != 1) # remove outlying replicate

highdepth_rich <- std_depth_rich %>%
  filter(read_depth > 2000) %>%
  filter(Replicate != 1) # remove outlying replicate

mean(lowdepth_rich$richness)
mean(highdepth_rich$richness)
```

""" 1500 read depth:

```{r}
lowdepth_rich <- std_depth_rich %>%
  filter(read_depth < 1500) %>%
  filter(Replicate != 1) # remove outlying replicate

highdepth_rich <- std_depth_rich %>%
  filter(read_depth > 1500) %>%
  filter(Replicate != 1) # remove outlying replicate

mean(lowdepth_rich$richness)
mean(highdepth_rich$richness)
```

""" 1000 read depth:

```{r}
lowdepth_rich <- std_depth_rich %>%
  filter(read_depth < 1000) %>%
  filter(Replicate != 1) # remove outlying replicate

highdepth_rich <- std_depth_rich %>%
  filter(read_depth > 1000) %>%
  filter(Replicate != 1) # remove outlying replicate

mean(lowdepth_rich$richness)
mean(highdepth_rich$richness)
```

It looks like richness starts to suffer below 1500 reads.

Low depth samples (< 2000 reads):

```{r}
samples_lowdepth <- std_depth_rich %>% 
  filter(read_depth < 2000) %>% 
  .$Sample

samples_lowdepth
length(samples_lowdepth)
```

Samples with low richness:

* Below 10 ASVs (and lowish depth)

```{r}
samples_lowrich <- std_depth_rich %>% 
  filter(richness < 20 & read_depth < 5000) %>%
  .$Sample

samples_lowrich
length(samples_lowrich)
```

Redo samples:

```{r}
samples_redo <- unique(c(samples_nostd, samples_lowstd, samples_lowdepth, samples_lowrich, "sa383"))

samples_redo
length(samples_redo)
```

### Rarefy

Due to the greater ead depth of replicate 1, I'll need to rarefy to reduce richness biases. However, rarefying will remove the standard from many of my samples.

I plan to rarefy to correct the richness bias imposed by differences in sequencing depth, but use the unrarefied data for analysis, with taxa that did not survive rarefication removed. Because I have an internal standard, sequencing depth biases on abundances shouldn't matter after I normalize.

Number of samples lost if I rarefy to 5k, 3k, 2.5k, and 2k reads:

```{r}
std_depth_rich %>% 
  filter(read_depth < 5000) %>% 
  nrow()

std_depth_rich %>% 
  filter(read_depth < 3000) %>% 
  nrow()

std_depth_rich %>% 
  filter(read_depth < 2500) %>% 
  nrow()

std_depth_rich %>% 
  filter(read_depth < 2000) %>% 
  nrow()
```

Which samples? 2.5k and 2k:

```{r}
std_depth_rich %>% 
  filter(read_depth < 2500) %>% 
  print()

std_depth_rich %>% 
  filter(read_depth < 2000) %>% 
  print()
```

I'll rarefy to 2500 and resequence the additional lost sample that is not already on the list.

```{r}
# Rarefy
physeq4 <- rarefy_even_depth(physeq3, 2500, rngseed=2021, replace=FALSE)
physeq4
```

Prune ASVs that did not pass the rarefication filter:

```{r}
tax_rarefied <- data.frame(tax_table(physeq4))
asvs_survived <- tax_rarefied %>% 
  rownames_to_column(var="ASV") %>% 
  .$ASV

# Remove taxa from non-rarefied data that did not pass rarefication
physeq5 <- prune_taxa(asvs_survived, physeq3)

physeq5
```

```{r}
count_processed2 <- data.frame(otu_table(physeq5))
depth_rich_processed2 <- count_processed2
```

Problem fixed or not?

```{r}
# Extract count table from phyloseq
count_processed2 <- data.frame(otu_table(physeq5))

# Calculate read depth per sample
read_depth2 <- count_processed2 %>% 
  head()

# Calculate richness
richness2 <- count_processed2 %>% 
  mutate(across(everything(), ~ if_else(.x > 0, 1, 0), {.cols})) %>%
  colSums() %>%
  data.frame() %>% 
  rownames_to_column(var="Sample")

#Merge
depth_rich_processed2 <- inner_join()

#ggplot
```


### Normalize to internal standard

```{r}
# Normalize
count_coversion <- count_processed %>%
  rownames_to_column(var="ASV") %>%
  gather(Sample, value, -ASV) %>%
  spread(ASV, value) %>%
  mutate(across(-Sample, ~ .x/`445e8681c3c1a735760e6c394f5f4d0a`, {.col}))



```







```{r, eval=FALSE, include=FALSE}
saveRDS(count_normalized, file="~/SFAgrowthrate/data_intermediate/SFA2_count_normalized.rds")
saveRDS(count_processed, file="~/SFAgrowthrate/data_intermediate/SFA2_count.rds")
saveRDS(tax_processed, file="~/SFAgrowthrate/data_intermediate/SFA2_taxonomy.rds")
#tree
#meta?

```



